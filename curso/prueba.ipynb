{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0dbe30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7de9884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://udemy.com/recommender-systems\n",
    "# https://deeplearningcourses.com/recommender-systems\n",
    "from __future__ import print_function, division\n",
    "from builtins import range, input\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from datetime import datetime\n",
    "from sortedcontainers import SortedList\n",
    "\n",
    "# load in the data\n",
    "import os\n",
    "if not os.path.exists('user2movie.json') or \\\n",
    "   not os.path.exists('movie2user.json') or \\\n",
    "   not os.path.exists('usermovie2rating.json') or \\\n",
    "   not os.path.exists('usermovie2rating_test.json'):\n",
    "   import preprocess2dict\n",
    "\n",
    "\n",
    "with open('user2movie.json', 'rb') as f:\n",
    "  user2movie = pickle.load(f)\n",
    "\n",
    "with open('movie2user.json', 'rb') as f:\n",
    "  movie2user = pickle.load(f)\n",
    "\n",
    "with open('usermovie2rating.json', 'rb') as f:\n",
    "  usermovie2rating = pickle.load(f)\n",
    "\n",
    "with open('usermovie2rating_test.json', 'rb') as f:\n",
    "  usermovie2rating_test = pickle.load(f)\n",
    "\n",
    "\n",
    "N = np.max(list(user2movie.keys())) + 1\n",
    "# the test set may contain movies the train set doesn't have data on\n",
    "m1 = np.max(list(movie2user.keys()))\n",
    "m2 = np.max([m for (u, m), r in usermovie2rating_test.items()])\n",
    "M = max(m1, m2) + 1\n",
    "print(\"N:\", N, \"M:\", M)\n",
    "\n",
    "if N > 10000:\n",
    "  print(\"N =\", N, \"are you sure you want to continue?\")\n",
    "  print(\"Comment out these lines if so...\")\n",
    "  exit()\n",
    "\n",
    "\n",
    "# to find the user similarities, you have to do O(N^2 * M) calculations!\n",
    "# in the \"real-world\" you'd want to parallelize this\n",
    "# note: we really only have to do half the calculations, since w_ij is symmetric\n",
    "K = 25 # number of neighbors we'd like to consider\n",
    "limit = 5 # number of common movies users must have in common in order to consider\n",
    "neighbors = [] # store neighbors in this list\n",
    "averages = [] # each user's average rating for later use\n",
    "deviations = [] # each user's deviation for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4560343",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_a = [usermovie2rating[(ii, movie)] for movie in common_movies]\n",
    "rating_b = [usermovie2rating[(jj, movie)] for movie in common_movies]\n",
    "ranking_matrix  = pd.DataFrame( [rating_a, rating_b])\n",
    "ranking_matrix.columns = common_movies\n",
    "pearson_sim = 1-pairwise_distances(ranking_matrix, metric=\"correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af222fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weight(movie2user, usermovie2rating):\n",
    "    count = 0\n",
    "    neighbors = {}  # store neighbors in this list\n",
    "    K = 25  # number of neighbors we'd like to consider\n",
    "    limit = 5  # number of common movies users must have in common in order to consider\n",
    "\n",
    "    for i in movie2user.keys():\n",
    "\n",
    "        print(i)\n",
    "        print(100 * (count / len(movie2user)))\n",
    "        count += 1\n",
    "\n",
    "        sl = SortedList()\n",
    "\n",
    "        users_i = movie2user[i]\n",
    "        users_i_set = set(users_i)\n",
    "\n",
    "        for j in movie2user.keys():\n",
    "\n",
    "            if i != j:\n",
    "                users_j = movie2user[j]\n",
    "                users_j_set = set(users_j)\n",
    "\n",
    "                common_users = (users_i_set & users_j_set)  # intersection\n",
    "                \n",
    "                if len(common_users) > limit:\n",
    "                    ratings_i = {user: usermovie2rating[(user, i)] for user in common_users}\n",
    "                    avg_i = np.mean(list(ratings_i.values()))\n",
    "                    dev_i = {user: (rating - avg_i) for user, rating in ratings_i.items()}\n",
    "                    dev_i_values = np.array(list(dev_i.values()))\n",
    "                    sigma_i = np.sqrt(dev_i_values.dot(dev_i_values))\n",
    "\n",
    "                    # # save these for later use\n",
    "                    # averages.append(avg_i)\n",
    "                    # deviations.append(dev_i)\n",
    "\n",
    "                    ratings_j = {user: usermovie2rating[(user, j)] for user in common_users}\n",
    "                    avg_j = np.mean(list(ratings_j.values()))\n",
    "                    dev_j = {user: (rating - avg_j) for user, rating in ratings_j.items()}\n",
    "                    dev_j_values = np.array(list(dev_j.values()))\n",
    "                    sigma_j = np.sqrt(dev_j_values.dot(dev_j_values))\n",
    "\n",
    "                    numerator = sum(dev_i[m] * dev_j[m] for m in common_users)\n",
    "                    w_ij = numerator / (sigma_i * sigma_j)\n",
    "\n",
    "                    sl.add((-w_ij, j))\n",
    "\n",
    "                    if len(sl) > K:\n",
    "                        del sl[-1]\n",
    "\n",
    "                # store the neighbors\n",
    "                neighbors[i] = sl\n",
    "\n",
    "    return neighbors\n",
    "\n",
    "neighbors = calculate_weight(movie2user, usermovie2rating)\n",
    "neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12445a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborns_m = neighbors[41]\n",
    "\n",
    "for w_ij, j in neighborns_m:\n",
    "    print(w_ij, j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f65f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate(i, m, neighbors, usermovie2rating, movie2user):\n",
    "    neighborns_m = neighbors[m]\n",
    "    users_m = movie2user[m]\n",
    "    averages_m = np.mean([usermovie2rating[(user, m)] for user in users_m])\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "\n",
    "    for w_ij, j in neighborns_m:\n",
    "\n",
    "        try:\n",
    "            users_j = movie2user[j]\n",
    "            ratings_j = {user: usermovie2rating[(user, j)] for user in users_j}\n",
    "            avg_j = np.mean(list(ratings_j.values()))\n",
    "\n",
    "            dev_j = usermovie2rating[(i, j)] - avg_j\n",
    "            numerator += dev_j * (- w_ij)\n",
    "            denominator += abs(w_ij)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if denominator == 0:\n",
    "        prediction = averages_i\n",
    "    else:\n",
    "        prediction = numerator / denominator + averages_m\n",
    "        prediction = min(5, prediction)\n",
    "        prediction = max(0.5, prediction)  # min rating is 0.5\n",
    "\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a62727",
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f6a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "calculate_rate(0, 41, neighbors, usermovie2rating, movie2user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21681f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "usermovie2rating[(0, 41)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f56d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725a2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 41\n",
    "j = 232\n",
    "users_i_set = set(movie2user[i])\n",
    "users_j_set = set(movie2user[j])\n",
    "common_users = (users_i_set & users_j_set)  # intersection\n",
    "\n",
    "ratings_i = {user: usermovie2rating[(user, i)] for user in common_users}\n",
    "ratings_j = {user: usermovie2rating[(user, j)] for user in common_users}\n",
    "ranking_matrix = pd.DataFrame([ratings_i, ratings_j], columns = list(common_users))\n",
    "pearson_sim = 1-pairwise_distances(ranking_matrix, metric=\"correlation\")\n",
    "pearson_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ba9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654faedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = np.max(list(user2movie.keys())) + 1\n",
    "# the test set may contain movies the train set doesn't have data on\n",
    "m1 = np.max(list(movie2user.keys()))\n",
    "m2 = np.max([m for (u, m), r in usermovie2rating_test.items()])\n",
    "M = max(m1, m2) + 1\n",
    "print(\"N:\", N, \"M:\", M)\n",
    "\n",
    "\n",
    "# initialize variables\n",
    "K = 10 # latent dimensionality\n",
    "W = np.random.randn(N, K)\n",
    "b = np.zeros(N)\n",
    "U = np.random.randn(M, K)\n",
    "c = np.zeros(M)\n",
    "mu = np.mean(list(usermovie2rating.values()))\n",
    "\n",
    "# prediction[i,j] = W[i].dot(U[j]) + b[i] + c.T[j] + mu\n",
    "\n",
    "def get_loss(d):\n",
    "  # d: (user_id, movie_id) -> rating\n",
    "  N = float(len(d))\n",
    "  sse = 0\n",
    "  for k, r in d.items():\n",
    "    i, j = k\n",
    "    p = W[i].dot(U[j]) + b[i] + c[j] + mu\n",
    "    sse += (p - r)*(p - r)\n",
    "  return sse / N\n",
    "\n",
    "\n",
    "# train the parameters\n",
    "epochs = 25\n",
    "reg =20. # regularization penalty\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(epochs):\n",
    "    print(\"epoch:\", epoch)\n",
    "    epoch_start = datetime.now()\n",
    "    # perform updates\n",
    "\n",
    "    # update W and b\n",
    "    t0 = datetime.now()\n",
    "    for i in range(N):\n",
    "    # for W\n",
    "        matrix = np.eye(K) * reg\n",
    "        vector = np.zeros(K)\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2fd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10 # latent dimensionality\n",
    "W = np.random.randn(N, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3406a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf464b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "U[[41,1512]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "U[[41,1512]].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7081a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "U[[41,1512]].dot(W[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2a6702",
   "metadata": {},
   "outputs": [],
   "source": [
    "W[0].T.dot(U[[41,1512]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfed88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user2movierating = {}\n",
    "for i, movies in user2movie.items():\n",
    "    r = np.array([usermovie2rating[(i,j)] for j in movies])\n",
    "    user2movierating[i] = (movies, r)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913760b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "user2movierating[4943]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ecfe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user2movierating = {}\n",
    "for i, movies in user2movie.items():\n",
    "    movies = [int(i) for i in movies]\n",
    "    r = np.array([usermovie2rating[(i,j)] for j in movies])\n",
    "    user2movierating[i] = (movies, r)\n",
    "movie2userrating = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ba0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie2userrating_test = {}\n",
    "\n",
    "for j, (users, r) in movie2userrating_test.items():\n",
    "    movie2userrating_test[j][1] = np.array(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a04d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43fa98cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docs = ['Well done!',\n",
    " 'Good work',\n",
    " 'Great effort',\n",
    " 'nice work',\n",
    " 'Excellent!',\n",
    " 'Weak',\n",
    " 'Poor effort!',\n",
    " 'not good',\n",
    " 'poor work',\n",
    " 'Could have done better.']\n",
    "# definir r√≥tulos de clase\n",
    "labels = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b4814ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29, 34], [2, 19], [2, 17], [8, 19], [19], [37], [17, 17], [29, 2], [17, 19], [18, 26, 34, 35]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aeafac66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29 34  0  0]\n",
      " [ 2 19  0  0]\n",
      " [ 2 17  0  0]\n",
      " [ 8 19  0  0]\n",
      " [19  0  0  0]\n",
      " [37  0  0  0]\n",
      " [17 17  0  0]\n",
      " [29  2  0  0]\n",
      " [17 19  0  0]\n",
      " [18 26 34 35]]\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56b6da59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d48fe7c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       "array([ 0.02726985,  0.01966386, -0.04280398, -0.01681539, -0.0282212 ,\n",
       "        0.02146066,  0.02144608,  0.03146023], dtype=float32)>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "a =Embedding(vocab_size, 8, input_length=max_length)(0)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e16942a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       "array([ 0.0102635 , -0.04784817,  0.0404448 , -0.04997382,  0.02917489,\n",
       "       -0.01177443, -0.03912998, -0.00837523], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2368a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# # compilar modelo\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# # resumir modelo\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "31f5bc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 4) dtype=float32 (created by layer 'embedding_27_input')>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a8887",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
